{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy import sqrt\n",
    "\n",
    "table_a = 'TableA'\n",
    "table_b = 'TableB'\n",
    "candidate_set = 'CandidateSet'\n",
    "prediction_set = 'PredictionList'\n",
    "\n",
    "dfa = pd.read_csv(table_a)\n",
    "dfb = pd.read_csv(table_b)\n",
    "dfc = pd.read_csv(candidate_set)\n",
    "dfp = pd.read_csv(prediction_set)\n",
    "\n",
    "shuffled_dfc = dfc.sample(frac=1)\n",
    "shuffled_dfc.to_csv('shuffled_dfc', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking Rules ( generates <em>ReducedCandidateSet.csv</em> )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all blocking rules...\n",
      "This will generate `ReducedCandidateSet.csv` after applying all blocking rules.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def blocking_rules():\n",
    "    print('Running all blocking rules...')\n",
    "    print('This will generate `ReducedCandidateSet.csv` after applying all blocking rules.')\n",
    "    new_cs = {}\n",
    "    j = 0\n",
    "    for i in range(len(shuffled_dfc)):\n",
    "        tuple = shuffled_dfc.iloc[i, :]\n",
    "        idxa = tuple.A_id; idxb = tuple.B_id\n",
    "        rowa = dfa.iloc[idxa, :]\n",
    "        rowb = dfb.iloc[idxb, :]\n",
    "        # Blocking Rule 1: Block all with missing `title` value\n",
    "        if type(rowa['title']) == str and type(rowb['title']) == str and len(rowa['title']) > 0 and len(rowb['title']) > 0:\n",
    "            # Blocking Rule 2: Block tuple pairs with non-matching `book_format`\n",
    "            if rowa['book_format'] == rowb['book_format']:\n",
    "                # Blocking Rule 3: Fraction of common words in title of tuple pairs > threshold(0.25)\n",
    "                atitle = re.sub('[^0-9a-zA-Z]+', ' ', rowa['title']).split(' ')\n",
    "                btitle = re.sub('[^0-9a-zA-Z]+', ' ', rowb['title']).split(' ')\n",
    "                common_words = list(set(atitle) & set(btitle))\n",
    "                total_words = list(set(atitle) | set(btitle))\n",
    "                fraction = len(common_words) / len(total_words)\n",
    "                if fraction > 0.10:\n",
    "                    new_cs[j] = tuple\n",
    "                    j = j+1\n",
    "        \n",
    "    updated_cdf = pd.DataFrame.from_dict(new_cs)\n",
    "    updated_cdf = updated_cdf.T\n",
    "    updated_cdf.to_csv('ReducedCandidateSet.csv', index=False)\n",
    "\n",
    "blocking_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Reduced Candidate Set:  1520\n"
     ]
    }
   ],
   "source": [
    "shuffled_dfc = pd.read_csv('ReducedCandidateSet.csv')\n",
    "print('Size of Reduced Candidate Set: ', len(shuffled_dfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in progres...\n",
      "This will return sample of 50 pairs. You may set value of `SAMPLE_SIZE` to get desired sample size.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SAMPLE_SIZE = 50\n",
    "\n",
    "def get_sample(start=0, n=50):\n",
    "    print('Running in progres...')\n",
    "    print('This will return sample of 50 pairs. You may set value of `SAMPLE_SIZE` to get desired sample size.')\n",
    "    matching_dict = {}\n",
    "    current_sample = {}\n",
    "    k = start\n",
    "    cols = dfa.columns.tolist()\n",
    "    cols.remove('Up_System')\n",
    "    cols.remove('_id')\n",
    "    cols = ['_id', 'Up_System', 'predicted', 'manual'] + cols\n",
    "    for i in range(len(shuffled_dfc[start:start+n])):\n",
    "        tuple = shuffled_dfc.iloc[start + i, :]\n",
    "        idxa = tuple.A_id; idxb = tuple.B_id\n",
    "        rowa = dfa.iloc[idxa, :]\n",
    "        rowb = dfb.iloc[idxb, :]\n",
    "        rowa['Up_System'] = str(start + i) + 'A'\n",
    "        rowb['Up_System'] = str(start + i) + 'B'\n",
    "        rowa['manual'] = ''\n",
    "        rowb['manual'] = ''\n",
    "        matching = dfp[(dfp['id1'] == rowa['_id']) & (dfp['id2'] == rowb['_id'])]\n",
    "        if len(matching) == 1 and matching['id1'].values[0] == rowa['_id'] and matching['id2'].values[0] == rowb['_id']:\n",
    "            matching_dict[str(rowa['_id']) + '_' + str(rowb['_id'])] = True\n",
    "            rowa['predicted'] = True\n",
    "            rowb['predicted'] = True\n",
    "        else:\n",
    "            rowa['predicted'] = False\n",
    "            rowb['predicted'] = False\n",
    "        current_sample[k] = pd.Series.to_dict(rowa)\n",
    "        current_sample[k+1] = pd.Series.to_dict(rowb)\n",
    "        k += 2\n",
    "\n",
    "    Sdf = pd.DataFrame.from_dict(current_sample)\n",
    "    Sdf = Sdf.T\n",
    "    Sdf.to_csv('labelled' + str(n) + '.csv', index=False, columns=cols)\n",
    "    # Sdf.to_csv('all1520.csv', index=False, columns=cols)\n",
    "    \n",
    "    print('Done.')\n",
    "\n",
    "\n",
    "get_sample(0, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to generate sample of 400 tuple pairs to manually label in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put 400 instead of 50 SAMPLE_SIZE to get sample of labelled pairs.\n",
    "get_sample(0, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Run after generating sample of 400 from above cell].\n",
    "### Manually label tuple pairs under the column <em>manual</em>. Then run this cell to generate labeled_pairs.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating `labeled_pairs.csv` file.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run this if you want to generate `labeled_pairs.csv` file.\n",
    "ldf = pd.read_csv('labelled400.csv')\n",
    "print('Generating `labeled_pairs.csv` file.')\n",
    "labelled_pairs = {}\n",
    "counter = 0\n",
    "for i in range(0, len(ldf), 2):\n",
    "    t1 = ldf.iloc[i, :]['_id']\n",
    "    t2 = ldf.iloc[i+1, :]['_id']\n",
    "    label = ldf.iloc[i, :]['manual']\n",
    "    if label == 1:\n",
    "        label = True\n",
    "    else:\n",
    "        label = False\n",
    "    labelled_pairs[counter] = {'id1': t1, 'id2': t2, 'label': label}\n",
    "    counter += 1\n",
    "\n",
    "lpdf = pd.DataFrame.from_dict(labelled_pairs)\n",
    "lpdf = lpdf.T\n",
    "lpdf.to_csv('labeled_pairs.csv', index=False)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
